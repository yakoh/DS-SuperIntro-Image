{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5VQJYsVGQfeJwQYuvYt6c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J5S3RO47m_VV"},"source":["## データの読み込み\n","mnistのデータを読み込んで、幾つかデータを見てみましょう。mnist.load_data()でデータをダウンロードし、pythonのオブジェクトとして利用できるようになります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDxC2rA1m_VY"},"outputs":[],"source":["import tensorflow as tf\n","mnist = tf.keras.datasets.mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"380k6Ajom_VZ"},"source":["データ件数を確認しておきましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WV_jbqUm_VZ"},"outputs":[],"source":["print(len(training_images), len(test_images))"]},{"cell_type":"markdown","metadata":{"id":"KGcKypOOm_VZ"},"source":["訓練用データ中のN枚目の画像のサイズや中身を詳細を見てみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYD5exuwm_Va"},"outputs":[],"source":["N=0\n","print(training_images[N].shape)\n","print(training_images[N])"]},{"cell_type":"markdown","metadata":{"id":"CsvXTb_km_Va"},"source":["N枚目の学習用画像とラベルを表示してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8M5VGDDm_Va"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","N=0\n","plt.imshow(training_images[N], cmap='Greys')\n","plt.show()\n","print('label=', training_labels[N])"]},{"cell_type":"markdown","metadata":{"id":"xgJeskW1m_Vb"},"source":["画像データの数値を [0, 1] に正規化しておきましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0v3Otklxm_Vb"},"outputs":[],"source":["training_images  = training_images / 255.0\n","test_images = test_images / 255.0"]},{"cell_type":"markdown","metadata":{"id":"LRMHOx4rm_Vb"},"source":["## NNによる画像認識\n","いよいよNNのモデルを作成します。3層構造で、中間層の数を5個、出力層は0から9のラベルに合わせて10個とします。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zx0CQgEHm_Vb"},"outputs":[],"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=5, activation='relu'))\n","model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"8UjSZyVfm_Vb"},"source":["上の例のように空のモデルを作成してから1層ずつ追加しても良いですし、次の例のようにSequential()への引数として3層の情報を渡して作成することもできます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZeL9_ybm_Vb"},"outputs":[],"source":["model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(5, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"]},{"cell_type":"markdown","metadata":{"id":"7Ws9hvOtm_Vc"},"source":["モデルができたら、compile()によって訓練方法を設定します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMKRcsxfm_Vc"},"outputs":[],"source":["model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"djgb5lmAm_Vc"},"source":["いよいよ訓練してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YRuscbbm_Vc"},"outputs":[],"source":["model.fit(training_images, training_labels, epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"tSTDRZvSm_Vc"},"source":["そこそこ良い性能が出たかも知れませんが、大事なのは汎化性能、すなわち訓練には用いていないデータに対して十分な性能を有するかどうかです。そこで、訓練には使用していないテストデータを用いて評価をしてみます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6wu3Kzbm_Vc"},"outputs":[],"source":["model.evaluate(test_images, test_labels)"]},{"cell_type":"markdown","metadata":{"id":"2oxlh4Bjm_Vc"},"source":["性能が不十分であれば、モデルを変更したり、訓練方法を見直すなどの手段を講じていきますが、その前に個別の認識結果を確認してみよう。まず、全テストデータの認識結果を保存しておきます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trRitjmlm_Vc"},"outputs":[],"source":["classifications = model.predict(test_images)"]},{"cell_type":"markdown","metadata":{"id":"96QR5xKAm_Vc"},"source":["1枚ずつ認識結果を見てみましょう。softmax層によって出力されるOne hot vectorは、要素の合計が1となるため、各々のラベルの確率を意味していると解釈できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2afc5Hym_Vc"},"outputs":[],"source":["import numpy as np\n","N=0\n","print(classifications[N])\n","print('prediction=', np.argmax(classifications[N]))\n","print('true label=', test_labels[N])\n","plt.imshow(test_images[N], cmap='Greys')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"H4jc8YG0m_Vd"},"source":["訓練したNNの規模を表示してみましょう。訓練の過程で調整したパラメータ数を確認できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRQedV7Hm_Vd"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"LDUWwBVmm_Vd"},"source":["## 訓練状況の可視化\n","訓練の進み具合をグラフ化してみましょう。fit()はepoch毎の評価値を履歴として返してくれるので、これを変数に保存しておけばすぐにグラフ化できます。verbose=0とすることで、途中経過を表示しないようにできます。validation_dataを与えることで、テストデータを用いた検証も同時に行うことができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd-ZH7ltm_Vd"},"outputs":[],"source":["train_hist=model.fit(training_images, training_labels, epochs=10, verbose=0,\n","                     validation_data=(test_images, test_labels))"]},{"cell_type":"markdown","metadata":{"id":"Ljbf99YQm_Vd"},"source":["グラフ化します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJszwM2tm_Vd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","figs, axs=plt.subplots(1, 2, figsize=(12, 4))\n","axs[0].plot(train_hist.history['loss'], label='training')\n","axs[0].plot(train_hist.history['val_loss'], label='validation')\n","axs[0].legend()\n","axs[0].set_xlabel('Epoch')\n","axs[0].set_ylabel('Loss')\n","axs[1].plot(train_hist.history['accuracy'], label='training')\n","axs[1].plot(train_hist.history['val_accuracy'], label='validation')\n","axs[1].legend()\n","axs[1].set_xlabel('Epoch')\n","axs[1].set_ylabel('Accuracy')\n","plt.show()"]}]}